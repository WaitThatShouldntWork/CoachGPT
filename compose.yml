# Docker compose file that allows each of the services we require to start
# only when their dependent service(s) have started. This is achieved through
# the use of a docker healthcheck for each service.

# First, construct private network for our services to communicate with each other
networks:
  network:
    driver: bridge

services:
  # neo4j service
  neo4j-db:
    image: neo4j:latest
    networks:
      - network
    environment:
      NEO4J_AUTH: ${NEO4J_USERNAME}/${NEO4J_PASSWORD}
    # network ports, we can customise exposed ports so that we
    # don't conflict with other neo4j instances that may be running.
    # if none are provided, we revert to defaults.
    ports:
      - ${NEO4J_HTTP_PORT:-7474}:7474 # HTTP for Neo4j Browser
      - ${NEO4J_BOLT_PORT:-7687}:7687 # Bolt port
    expose:
      - ${NEO4J_HTTP_PORT:-7474}
      - ${NEO4J_BOLT_PORT:-7687}
    healthcheck:
      test: wget http://neo4j-db:7474 || exit 1
      interval: 60s
      timeout: 10s
      retries: 5
      start_interval: 5s
      start_period: 60s

  # InferGPT Backend
  backend:
    image: infergpt/backend
    build:
      context: backend
      dockerfile: ./Dockerfile
    environment:
      NEO4J_URI: bolt://neo4j-db:7687
      NEO4J_USERNAME: ${NEO4J_USERNAME}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      MODEL: ${MODEL}
      MISTRAL_KEY: ${MISTRAL_KEY}
      FRONTEND_URL: ${FRONTEND_URL}
    depends_on:
      neo4j-db:
        condition: service_healthy
    networks:
      - network
    ports:
      - 8250:8250
    healthcheck:
      test: wget http://backend:8250/health || exit 1
      interval: 60s
      timeout: 10s
      retries: 5
      start_interval: 5s
      start_period: 60s

  # InferGPT Frontend
  frontend:
    image: infergpt/frontend
    build:
      context: frontend
      dockerfile: ./Dockerfile
    environment:
      BACKEND_URL: ${BACKEND_URL}
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - network
    ports:
      - 8650:8650
    expose:
      - 8650
